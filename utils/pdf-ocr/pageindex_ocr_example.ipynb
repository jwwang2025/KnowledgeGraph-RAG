{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIjn2vW1ooxz"
      },
      "source": [
        "### 1ï¸âƒ£ å®‰è£… SDK\n",
        "è¿è¡Œä¸‹æ–¹å•å…ƒæ ¼ä»¥å®‰è£… PageIndex OCR SDKã€‚è¯¥æ“ä½œä»…éœ€åœ¨ä½ çš„ç¯å¢ƒä¸­æ‰§è¡Œä¸€æ¬¡ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY9af_12oox0",
        "outputId": "67c620b7-e420-48b4-9fd8-948796048d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pageindex in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (0.1.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from pageindex) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pageindex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mgLrLd6oox0"
      },
      "source": [
        "### 2ï¸âƒ£ åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
        "\n",
        "å¯¼å…¥ PageIndex å®¢æˆ·ç«¯ç±»ï¼Œå¹¶ä½¿ç”¨ä½ çš„ API å¯†é’¥å®Œæˆèº«ä»½éªŒè¯ã€‚è¯·åŠ¡å¿…å¦¥å–„ä¿ç®¡ä½ çš„ API å¯†é’¥ï¼Œåˆ‡å‹¿å…¬å¼€åˆ†äº«ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr9JN4Tsoox0"
      },
      "outputs": [],
      "source": [
        "from pageindex import PageIndexClient\n",
        "\n",
        "# Paste your API key here, you can get the api key from https://dash.pageindex.ai/api-keys\n",
        "API_KEY = \"API_KEY\"\n",
        "pi_client = PageIndexClient(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIFjkH2oox0"
      },
      "source": [
        "### 3ï¸âƒ£ æäº¤ PDF æ–‡æ¡£ä»¥è¿›è¡Œ OCR è¯†åˆ«\n",
        "\n",
        "ä½¿ç”¨å®¢æˆ·ç«¯ä¸Šä¼  PDF æ–‡ä»¶æ‰§è¡Œ OCR è¯†åˆ«å¤„ç†ï¼ˆå½“å‰ä»…æ”¯æŒ PDF æ–‡ä»¶æ ¼å¼ï¼‰ã€‚\n",
        "\n",
        "æäº¤å®Œæˆåï¼Œä½ ä¼šè·å–ä¸€ä¸ªdoc_idï¼Œå¯ç”¨äºæŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ä»¥åŠè·å– OCR è¯†åˆ«ç»“æœã€‚\n",
        "\n",
        "> å¦‚éœ€æ›¿æ¢æ–‡ä»¶ï¼Œè¯·å°†ä¸‹æ–¹çš„æ–‡ä»¶è·¯å¾„ä¿®æ”¹ä¸ºä½ æœ¬åœ°çš„ PDF æ–‡ä»¶è·¯å¾„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znRzYxHQoox0",
        "outputId": "5996ee99-bd84-4684-8f6c-575a4d1d07d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded file to: ../data/2501.12948.pdf\n",
            "Document submitted. Document ID: pi-cmdx77gn0003108poki6h7cpc\n"
          ]
        }
      ],
      "source": [
        "import requests, os\n",
        "\n",
        "pdf_url = \"https://arxiv.org/pdf/2501.12948.pdf\"\n",
        "pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
        "os.makedirs(os.path.dirname(pdf_path), exist_ok=True)\n",
        "\n",
        "response = requests.get(pdf_url)\n",
        "with open(pdf_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Downloaded file to: {pdf_path}\")\n",
        "result = pi_client.submit_document(pdf_path)\n",
        "doc_id = result[\"doc_id\"]\n",
        "print(f\"Document submitted. Document ID: {doc_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYyFY2aXoox0"
      },
      "source": [
        "### 4ï¸âƒ£ æŸ¥è¯¢å¤„ç†çŠ¶æ€å¹¶è·å– OCR è¯†åˆ«ç»“æœ\n",
        "\n",
        "OCR è¯†åˆ«å¤„ç†è€—æ—¶å› æ–‡ä»¶å¤§å°è€Œå¼‚ï¼šå°æ–‡ä»¶ä»…éœ€æ•°ç§’ï¼Œå¤§æ–‡ä»¶åˆ™å¯èƒ½éœ€è¦æ•°åˆ†é’Ÿã€‚\n",
        "\n",
        "ä»¥ä¸‹ä»£ç ä¼šæ¯éš” 3 ç§’è½®è¯¢ä¸€æ¬¡æœåŠ¡çŠ¶æ€ï¼Œæœ€é•¿è½®è¯¢æ—¶é•¿ä¸º 5 åˆ†é’Ÿã€‚å¾…å¤„ç†å®Œæˆåï¼Œä»£ç ä¼šé¢„è§ˆæå–å‡ºçš„ç¬¬ä¸€é¡µæ–‡æœ¬å†…å®¹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "E5NFI1XRoox1",
        "outputId": "c03cbf31-d4c3-4d08-97fb-847587cdb371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OCR Results ready!\n",
            "Page 1 (partial content):\n",
            "\n",
            "# DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
            "\n",
            "DeepSeek-AI<br>research@deepseek.com\n",
            "\n",
            "\n",
            "## Abstract\n",
            "\n",
            "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Simple polling\n",
        "for attempt in range(60):  # Try up to 300s (100 x 3s)\n",
        "    ocr_result = pi_client.get_ocr(doc_id)\n",
        "    if ocr_result[\"status\"] == \"completed\":\n",
        "        print(\"OCR Results ready!\")\n",
        "        break\n",
        "    elif ocr_result[\"status\"] == \"failed\":\n",
        "        print(\"OCR failed.\")\n",
        "        break\n",
        "    time.sleep(3)\n",
        "else:\n",
        "    print(\"Still processing after 10 minutes. Try again later.\")\n",
        "\n",
        "# Preview the first page's markdown\n",
        "if ocr_result.get(\"status\") == \"completed\":\n",
        "    if ocr_result[\"result\"]:\n",
        "        first_page = ocr_result[\"result\"][0]\n",
        "        print(f\"Page {first_page['page_index']} (partial content):\\n\")\n",
        "        print(first_page[\"markdown\"][:1000])  # Print first 1000 chars\n",
        "    else:\n",
        "        print(\"No pages found in OCR result.\")\n",
        "else:\n",
        "    print(\"OCR not completed yet. Try again later.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rotrPbMWgK7y"
      },
      "outputs": [],
      "source": [
        "def extract_toc_from_json(data, indent_size=2):\n",
        "    headings = []\n",
        "\n",
        "    def extract_from_nodes(nodes, parent_level=0):\n",
        "        if isinstance(nodes, list):\n",
        "            for node in nodes:\n",
        "                if isinstance(node, dict):\n",
        "                    # å…ˆå¤„ç†èŠ‚ç‚¹è‡ªèº«çš„æ ‡é¢˜\n",
        "                    if 'title' in node:\n",
        "                        page_idx = node.get('page_index', 0)\n",
        "                        headings.append((parent_level + 1, node['title'], page_idx, len(headings)))\n",
        "\n",
        "                    # å†å¤„ç†å­èŠ‚ç‚¹\n",
        "                    if 'nodes' in node:\n",
        "                        extract_from_nodes(node['nodes'], parent_level + 1)\n",
        "        elif isinstance(nodes, dict):\n",
        "            # å…ˆå¤„ç†èŠ‚ç‚¹è‡ªèº«çš„æ ‡é¢˜\n",
        "            if 'title' in nodes:\n",
        "                page_idx = nodes.get('page_index', 0)\n",
        "                headings.append((parent_level + 1, nodes['title'], page_idx, len(headings)))\n",
        "\n",
        "            # å†å¤„ç†å­èŠ‚ç‚¹\n",
        "            if 'nodes' in nodes:\n",
        "                extract_from_nodes(nodes['nodes'], parent_level + 1)\n",
        "\n",
        "    if isinstance(data, dict) and 'pages' in data:\n",
        "        for page in data['pages']:\n",
        "            if 'markdown' in page:\n",
        "                page_idx = page.get('page_index', 0)\n",
        "                extracted = _extract_headings_from_markdown(page['markdown'], page_idx)\n",
        "                for level, title, _ in extracted:\n",
        "                    headings.append((level, title, page_idx, len(headings)))\n",
        "    else:\n",
        "        extract_from_nodes(data, -1)  # ä»-1å¼€å§‹ï¼Œè¿™æ ·ç¬¬ä¸€çº§æ ‡é¢˜çš„levelæ˜¯0\n",
        "\n",
        "    toc_lines = []\n",
        "    for level, title, page_index, order in headings:\n",
        "        indent = '  ' * level\n",
        "        toc_lines.append(f\"{indent}- {title}\")\n",
        "\n",
        "    return '\\n'.join(toc_lines)\n",
        "\n",
        "def _extract_headings_from_markdown(markdown_content, page_index=0):\n",
        "    import re\n",
        "    headings = []\n",
        "    heading_pattern = r'^(#{1,6})\\s+(.+)$'\n",
        "\n",
        "    for line in markdown_content.split('\\n'):\n",
        "        match = re.match(heading_pattern, line.strip())\n",
        "        if match:\n",
        "            level = len(match.group(1))\n",
        "            title = re.sub(r'\\s+', ' ', match.group(2).strip())\n",
        "            if title:\n",
        "                headings.append((level, title, page_index))\n",
        "\n",
        "    return headings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBgnTpNJoox1"
      },
      "source": [
        "### 5ï¸âƒ£ è·å–æ–‡æ¡£æ ‘å½¢ç»“æ„\n",
        "\n",
        "ä½ ä¹Ÿå¯ä»¥é€šè¿‡ä¸‹æ–¹æ–¹æ³•è·å–è¯¥æ–‡æ¡£çš„ PageIndex æ ‘å½¢ç»“æ„ã€‚è‹¥æ ‘å½¢ç»“æ„æš‚æœªç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eByds2lsgK7y",
        "outputId": "07b3d51a-1379-4f21-a0df-ab3ca39ddc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document tree structure loaded!\n",
            "\n",
            "## Tree Structure (drop text fields)\n",
            "\n",
            "[{'title': 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via '\n",
            "           'Reinforcement Learning',\n",
            "  'node_id': '0000',\n",
            "  'page_index': 1,\n",
            "  'nodes': [{'title': 'Abstract', 'node_id': '0001', 'page_index': 1},\n",
            "            {'title': 'Contents', 'node_id': '0002', 'page_index': 2},\n",
            "            {'title': '1. Introduction',\n",
            "             'node_id': '0003',\n",
            "             'page_index': 3,\n",
            "             'nodes': [{'title': '1.1. Contributions',\n",
            "                        'node_id': '0004',\n",
            "                        'page_index': 4},\n",
            "                       {'title': '1.2. Summary of Evaluation Results',\n",
            "                        'node_id': '0005',\n",
            "                        'page_index': 4}]},\n",
            "            {'title': '2. Approach',\n",
            "             'node_id': '0006',\n",
            "             'page_index': 5,\n",
            "             'nodes': [{'title': '2.1. Overview',\n",
            "                        'node_id': '0007',\n",
            "                        'page_index': 5},\n",
            "                       {'title': '2.2. DeepSeek-R1-Zero: Reinforcement '\n",
            "                                 'Learning on the Base Model',\n",
            "                        'node_id': '0008',\n",
            "                        'page_index': 5,\n",
            "                        'nodes': [{'title': '2.2.1. Reinforcement Learning '\n",
            "                                            'Algorithm',\n",
            "                                   'node_id': '0009',\n",
            "                                   'page_index': 5},\n",
            "                                  {'title': '2.2.2. Reward Modeling',\n",
            "                                   'node_id': '0010',\n",
            "                                   'page_index': 6},\n",
            "                                  {'title': '2.2.3. Training Template',\n",
            "                                   'node_id': '0011',\n",
            "                                   'page_index': 6},\n",
            "                                  {'title': '2.2.4. Performance, '\n",
            "                                            'Self-evolution Process and Aha '\n",
            "                                            'Moment of DeepSeek-R1-Zero',\n",
            "                                   'node_id': '0012',\n",
            "                                   'page_index': 6}]},\n",
            "                       {'title': '2.3. DeepSeek-R1: Reinforcement Learning '\n",
            "                                 'with Cold Start',\n",
            "                        'node_id': '0013',\n",
            "                        'page_index': 9,\n",
            "                        'nodes': [{'title': '2.3.1. Cold Start',\n",
            "                                   'node_id': '0014',\n",
            "                                   'page_index': 9},\n",
            "                                  {'title': '2.3.2. Reasoning-oriented '\n",
            "                                            'Reinforcement Learning',\n",
            "                                   'node_id': '0015',\n",
            "                                   'page_index': 10},\n",
            "                                  {'title': '2.3.3. Rejection Sampling and '\n",
            "                                            'Supervised Fine-Tuning',\n",
            "                                   'node_id': '0016',\n",
            "                                   'page_index': 10},\n",
            "                                  {'title': '2.3.4. Reinforcement Learning for '\n",
            "                                            'all Scenarios',\n",
            "                                   'node_id': '0017',\n",
            "                                   'page_index': 11}]},\n",
            "                       {'title': '2.4. Distillation: Empower Small Models with '\n",
            "                                 'Reasoning Capability',\n",
            "                        'node_id': '0018',\n",
            "                        'page_index': 11}]},\n",
            "            {'title': '3. Experiment',\n",
            "             'node_id': '0019',\n",
            "             'page_index': 11,\n",
            "             'nodes': [{'title': '3.1. DeepSeek-R1 Evaluation',\n",
            "                        'node_id': '0020',\n",
            "                        'page_index': 13},\n",
            "                       {'title': '3.2. Distilled Model Evaluation',\n",
            "                        'node_id': '0021',\n",
            "                        'page_index': 14}]},\n",
            "            {'title': '4. Discussion',\n",
            "             'node_id': '0022',\n",
            "             'page_index': 14,\n",
            "             'nodes': [{'title': '4.1. Distillation v.s. Reinforcement '\n",
            "                                 'Learning',\n",
            "                        'node_id': '0023',\n",
            "                        'page_index': 14},\n",
            "                       {'title': '4.2. Unsuccessful Attempts',\n",
            "                        'node_id': '0024',\n",
            "                        'page_index': 15}]},\n",
            "            {'title': '5. Conclusion, Limitations, and Future Work',\n",
            "             'node_id': '0025',\n",
            "             'page_index': 16},\n",
            "            {'title': 'References', 'node_id': '0026', 'page_index': 17},\n",
            "            {'title': 'Appendix', 'node_id': '0027', 'page_index': 20},\n",
            "            {'title': 'A. Contributions and Acknowledgments',\n",
            "             'node_id': '0028',\n",
            "             'page_index': 20,\n",
            "             'nodes': [{'title': 'Core Contributors',\n",
            "                        'node_id': '0029',\n",
            "                        'page_index': 20},\n",
            "                       {'title': 'Contributors',\n",
            "                        'node_id': '0030',\n",
            "                        'page_index': 20}]}]}]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def remove_text_fields(data):\n",
        "    if isinstance(data, dict):\n",
        "        return {k: remove_text_fields(v) for k, v in data.items() if k != 'text'}\n",
        "    elif isinstance(data, list):\n",
        "        return [remove_text_fields(item) for item in data]\n",
        "    return data\n",
        "\n",
        "tree_result = pi_client.get_tree(doc_id)\n",
        "# print the tree structure\n",
        "if tree_result.get(\"status\") == \"completed\":\n",
        "    print(\"Document tree structure loaded!\")\n",
        "    toc = extract_toc_from_json(tree_result.get(\"result\"))\n",
        "\n",
        "    print(\"\\n## Tree Structure (drop text fields)\\n\")\n",
        "    pprint(remove_text_fields(tree_result.get(\"result\")),sort_dicts=False)\n",
        "else:\n",
        "    print(f\"Tree status: {tree_result.get('status')}. Try again later if still processing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwR0ooMZoox1",
        "outputId": "87837b70-b347-497d-a995-0eada78559f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document tree structure loaded!\n",
            "- DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
            "  - Abstract\n",
            "  - Contents\n",
            "  - 1. Introduction\n",
            "    - 1.1. Contributions\n",
            "    - 1.2. Summary of Evaluation Results\n",
            "  - 2. Approach\n",
            "    - 2.1. Overview\n",
            "    - 2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\n",
            "      - 2.2.1. Reinforcement Learning Algorithm\n",
            "      - 2.2.2. Reward Modeling\n",
            "      - 2.2.3. Training Template\n",
            "      - 2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero\n",
            "    - 2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\n",
            "      - 2.3.1. Cold Start\n",
            "      - 2.3.2. Reasoning-oriented Reinforcement Learning\n",
            "      - 2.3.3. Rejection Sampling and Supervised Fine-Tuning\n",
            "      - 2.3.4. Reinforcement Learning for all Scenarios\n",
            "    - 2.4. Distillation: Empower Small Models with Reasoning Capability\n",
            "  - 3. Experiment\n",
            "    - 3.1. DeepSeek-R1 Evaluation\n",
            "    - 3.2. Distilled Model Evaluation\n",
            "  - 4. Discussion\n",
            "    - 4.1. Distillation v.s. Reinforcement Learning\n",
            "    - 4.2. Unsuccessful Attempts\n",
            "  - 5. Conclusion, Limitations, and Future Work\n",
            "  - References\n",
            "  - Appendix\n",
            "  - A. Contributions and Acknowledgments\n",
            "    - Core Contributors\n",
            "    - Contributors\n"
          ]
        }
      ],
      "source": [
        "if tree_result.get(\"status\") == \"completed\":\n",
        "    print(\"Document tree structure loaded!\")\n",
        "    toc = extract_toc_from_json(tree_result.get(\"result\"))\n",
        "    print(toc)\n",
        "else:\n",
        "    print(f\"Tree status: {tree_result.get('status')}. Try again later if still processing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRmOOrTBoox1"
      },
      "source": [
        "### 6ï¸âƒ£ åˆ é™¤æ–‡æ¡£ï¼ˆæ¸…ç†æ“ä½œï¼‰\n",
        "\n",
        "è‹¥ä½ ä¸å†éœ€è¦è¯¥æ–‡æ¡£ï¼Œå¯è¿è¡Œä¸‹æ–¹ä»£ç å°†å…¶åˆ é™¤ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbSbEwWUoox1"
      },
      "outputs": [],
      "source": [
        "pi_client.delete_document(doc_id)\n",
        "print(\"Document deleted successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAzzxjooox1"
      },
      "source": [
        "## ğŸ’¬ æ³¨æ„äº‹é¡¹\n",
        "\n",
        "- ç›®å‰ä»…æ”¯æŒPDF æ–‡ä»¶æ ¼å¼ã€‚"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
